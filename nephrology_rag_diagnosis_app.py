import streamlit as st
from PIL import Image
import io
import re
import json
import csv
import base64
from io import BytesIO
from docx import Document
from sentence_transformers import SentenceTransformer
import faiss
from google.cloud import vision
import os

# Streamlit ì„¤ì •
st.set_page_config(page_title="ì‹ ì¥ë‚´ê³¼ ì§„ë‹¨ ì‹œìŠ¤í…œ", layout="centered")
st.title("ğŸ§œï¸ ì‹ ì¥ë‚´ê³¼ ì§€ë°© ì˜ˆì¸¡ ì‹œìŠ¤í…œ")

st.markdown("""
ì´ ì‹œìŠ¤í…œì€ ì‹ ì¥ë‚´ê³¼ ì§€ë°©êµ°(ì˜ˆ: CKD, AKI, Nephrotic Syndrome ë“±)ì— ëŒ€í•´
í˜‘ì•…ê²€ì‚¬ ìˆ˜ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§€ë°©ì„ ë³´ì¡°í•˜ê³ ,
ì§€ë°©ì— ê´€í•œ ì§ˆë¬¸ì— êµ¬ê²© ê¸°ë°˜ ì‘ë‹µì„ ì œê³µí•˜ëŠ” **AI ê¸°ë°˜ ì§€ë°© ì§€ì› ë„êµ¬**ì…ë‹ˆë‹¤.

**ê¸°ëŠ¥ ì†Œê°œ:**
1. ìˆ˜ì¹˜ ì§ì ‘ ì…ë ¥ ë˜ëŠ” ê²€ì‚¬ ì´ë¯¸ì§€ ì—…ë¡œë“œ(Google OCR ê¸°ë°˜)
2. ë¢° ê¸°ë°˜ ì§€ë°© ë° ë¦¬í¬íŠ¸ ì €ì¥
3. RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ (ìœ ì‚¬ ë¬¸ì„œ ë° AI ì„¤ëª…)
""")

st.header("ğŸ¦¢ ê²€ì‚¬ ìˆ˜ì¹˜ ì…ë ¥")

with st.form("manual_input_form"):
    eGFR = st.number_input("eGFR (mL/min/1.73mÂ²)", min_value=0.0, max_value=200.0, step=0.1)
    creatinine = st.number_input("Creatinine (mg/dL)", min_value=0.0, max_value=20.0, step=0.1)
    albumin = st.number_input("Albumin (g/dL)", min_value=0.0, max_value=6.0, step=0.1)
    proteinuria = st.number_input("ë‹¨ë°±ì¡° (mg/dL)", min_value=0.0, max_value=5000.0, step=1.0)
    submitted = st.form_submit_button("ì§€ë°© ê²°ê³¼ í™•ì¸")

def run_rag_from_input(eGFR, creatinine, albumin, proteinuria):
    user_question = f"eGFR: {eGFR}, Creatinine: {creatinine}, Albumin: {albumin}, ë‹¨ë°±ì¡°: {proteinuria} ì´ ìˆ˜ì¹˜ë¡œ ì–´ëŠ ì§€ë°©ì´ ì˜ì‹¬ë©ë‹ˆê¹Œ?"
    st.subheader("ğŸ” RAG ê¸°ë°˜ ê²°ê³¼ ë¶„ì„")
    st.write(f"\2753 ìë™ ìƒì„± ì§ˆì˜: {user_question}")

    model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')
    question_embedding = model.encode([user_question])
    index = faiss.read_index("nephro_faiss.index")

    with open("nephro_chunks.json", "r", encoding="utf-8") as f:
        chunks = json.load(f)

    D, I = index.search(question_embedding, k=2)
    matched_docs = []
    for idx, score in zip(I[0], D[0]):
        matched_docs.append({
            "title": f"ê´€ë ¨ ë¬¸ì„œ #{idx+1}",
            "similarity": round(1.0 / (1.0 + score), 2),
            "snippet": chunks[idx][:200] + "..." if len(chunks[idx]) > 200 else chunks[idx]
        })

    st.markdown("### ğŸ”— ê²€ì‚¬ëœ ë¬¸ì„œ ë° ìœ ì‚¬ë„")
    for doc in matched_docs:
        st.write(f"ğŸ“„ **{doc['title']}** â€” ìœ ì‚¬ë„: {int(doc['similarity'] * 100)}%")
        st.caption(f"â¤ï¸ {doc['snippet']}")

    llm_answer = "(ì˜ˆì‹œ ì‘ë‹µ) ì…ë ¥ëœ ìˆ˜ì¹˜ëŠ” CKD, Nephrotic Syndrome ë“±ê³¼ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •í™•í•œ ì§„ë‹¨ì€ ì˜ë£Œì§„ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤."
    st.markdown("### ğŸ¤– AI ì‘ë‹µ ì˜ˆì‹œ")
    st.success(llm_answer)

if submitted:
    st.subheader("ğŸ©º ì˜ˆë¹„ ì§€ë°© ê²°ê³¼")
    result = []
    if eGFR < 60:
        result.append("ğŸ”¸ CKD ê°€ëŠ¥ì„± ìˆìŒ (eGFR < 60)")
    if creatinine > 1.3:
        result.append("ğŸ”¸ ì‹ ê¸°ëŠ¥ ì €í•˜ ê°€ëŠ¥ì„± (Creatinine > 1.3)")
    if albumin < 3.5:
        result.append("ğŸ”¸ ì €ì•Œë¶€ë¯¼í˜•ì¦ ê°€ëŠ¥ì„±")
    if proteinuria > 150:
        result.append("ğŸ”¸ ë‹¨ë°±ì¡° ì˜ì‹¬ (ì •ìƒ ê¸°ì¤€ ì´ˆê³¼)")
    if result:
        for r in result:
            st.write(r)
    else:
        st.success("ì •ìƒ ë²”ìœ„ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")

    run_rag_from_input(eGFR, creatinine, albumin, proteinuria)

st.markdown("---")

st.subheader("ğŸ“· ì´ë¯¸ì§€ OCR ì—…ë¡œë“œ (Google Vision API)")
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ (png, jpg, jpeg)", type=["png", "jpg", "jpeg"])

if uploaded_file:
    image = Image.open(uploaded_file)
    images = [image]

    extracted_text = ""
    client = vision.ImageAnnotatorClient()
    for img in images:
        img_byte_arr = io.BytesIO()
        img.save(img_byte_arr, format='PNG')
        content = img_byte_arr.getvalue()
        image_for_vision = vision.Image(content=content)
        response = client.text_detection(image=image_for_vision)
        texts = response.text_annotations
        if texts:
            extracted_text += texts[0].description + "\n"

    st.text_area("ğŸ“ OCR ì¸ì‹ ê²°ê³¼:", extracted_text, height=200)

    def extract_value(name):
        match = re.search(fr"{name}[:=\s]*([0-9]+\.?[0-9]*)", extracted_text, re.IGNORECASE)
        return float(match.group(1)) if match else 0.0

    eGFR_val = extract_value("eGFR")
    creat_val = extract_value("Creatinine")
    alb_val = extract_value("Albumin")
    prot_val = extract_value("ë‹¨ë°±ì¡°|Proteinuria")

    st.write("**ğŸ“Œ ì¶”ì¶œëœ ê²€ì‚¬ ìˆ˜ì¹˜:**")
    st.write(f"eGFR: {eGFR_val}, Creatinine: {creat_val}, Albumin: {alb_val}, ë‹¨ë°±ì¡°: {prot_val}")

    run_rag_from_input(eGFR_val, creat_val, alb_val, prot_val)

st.markdown("---")

st.subheader("ğŸ¤– ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ (RAG ê¸°ë°˜)")
user_question = st.text_input("ì˜ˆ: 'eGFRì´ 55ì¸ë° CKDì¸ê°€ìš”?' ë˜ëŠ” 'ë‹¨ë°±ë‡¨ ìˆ˜ì¹˜ê°€ ë†’ìœ¼ë©´ ì–´ë–¤ ì˜ë¯¸ì¸ê°€ìš”?'")

if user_question:
    model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')
    question_embedding = model.encode([user_question])
    index = faiss.read_index("nephro_faiss.index")

    with open("nephro_chunks.json", "r", encoding="utf-8") as f:
        chunks = json.load(f)

    D, I = index.search(question_embedding, k=2)
    matched_docs = []
    for idx, score in zip(I[0], D[0]):
        matched_docs.append({
            "title": f"ê´€ë ¨ ë¬¸ì„œ #{idx+1}",
            "similarity": round(1.0 / (1.0 + score), 2),
            "snippet": chunks[idx][:200] + "..." if len(chunks[idx]) > 200 else chunks[idx]
        })

    st.markdown("### ğŸ”— ê²€ì‚¬ëœ ë¬¸ì„œ ë° ìœ ì‚¬ë„")
    for doc in matched_docs:
        st.write(f"ğŸ“„ **{doc['title']}** â€” ìœ ì‚¬ë„: {int(doc['similarity'] * 100)}%")
        st.caption(f"â¤ï¸ {doc['snippet']}")

    llm_answer = "(ì˜ˆì‹œ ì‘ë‹µ) ì…ë ¥í•˜ì‹  ê²€ì‚¬ ìˆ˜ì¹˜ëŠ” CKDì™€ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³´ë‹¤ ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ ì˜ë£Œì§„ì˜ í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤."

    st.markdown("### ğŸ¤– AI ì‘ë‹µ ì˜ˆì‹œ")
    st.success(llm_answer)

    if st.button("ğŸ“„ ì§ˆì˜ì‘ë‹µ ë³´ê³ ì„œ ì €ì¥ (DOCX)"):
        doc = Document()
        doc.add_heading("RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ê²°ê³¼ ë¦¬í¬íŠ¸", level=1)
        doc.add_paragraph(f"ì‚¬ìš©ì ì§ˆë¬¸: {user_question}")

        doc.add_heading("ê²€ì‚¬ëœ ë¬¸ì„œ", level=2)
        for doc_data in matched_docs:
            doc.add_paragraph(f"- {doc_data['title']} (ìœ ì‚¬ë„: {int(doc_data['similarity']*100)}%)")
            doc.add_paragraph(f"  â¤· {doc_data['snippet']}")

        doc.add_heading("AI ì‘ë‹µ", level=2)
        doc.add_paragraph(llm_answer)

        buffer = BytesIO()
        doc.save(buffer)
        st.download_button("DOCX ë‹¤ìš´ë¡œë“œ", data=buffer.getvalue(), file_name="ì§ˆì˜ì‘ë‹µ_ë¦¬í¬íŠ¸.docx")
